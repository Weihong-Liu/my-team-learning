# Task05 提前阅读并完成第6章期中大作业
## 1 面试题
### 1.1 简述Hadoop小文件弊端
HDFS小文件的弊端：HDFS上每个小文件都要在NameNode上建立一个索引，这个索引大小约为150byte，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用NameNode的内存空间，另一方面就是索引文件过大使得索引速度变慢。
hdfs使用于高吞吐量，不适合低时间延迟的访问，如果同时存入大量的小文件会花费很长的使时间。
流式读取的方式，不适合多用户写入，以及任意位置写入。如果访问小文件，则必须从一个datanode跳转到另外一个datanode，这样大大降低了读取性能。
### 1.2 HDFS中DataNode挂掉如何处理？
部分节点的datanode消失后，除了格式化hdfs并删除相应文件 的方法之外，还有一种简单可行的方法是恢复快照，直接回到之前状态。

### 1.3 HDFS中NameNode挂掉如何处理？
挂掉后首先肯定是进行重启,如果时间段比较高峰期,肯定要快速移动文件进行复原,等错过高峰进行事故分析。然后将SecondaryNameNode中数据拷贝到namenode存储数据的目录；

### 1.4 HBase读写流程？
Hbase的写入数据流程：
1. 由客户端发起写数据请求，首先会与zookeeper建立连接
2. 从zookeeper中获取hbase:meta表被哪一个regionserver所管理
3. 连接hbase:meta表中获取对应的regionserver地址 (从meta表中获取当前要写入数据的表对应的region所管理的regionserver) 只会返回一个regionserver地址
4. 与要写入数据的regionserver建立连接，然后开始写入数据，将数据首先会写入到HLog，然后将数据写入到对应store模块中的memstore中
（可能会写多个），当这两个地方都写入完成之后，表示数据写入完成。
HBase数据的读取流程：
1.Client访问zookeeper，获取元数据存储所在的regionserver
2.通过刚刚获取的地址访问对应的regionserver，拿到对应的表存储的regionserver
3.去表所在的regionserver进行数据的读取
4.查找对应的region，在region中寻找列族，先找到memstore，找不到去blockcache中寻找，再找不到就进行storefile的遍历
5.找到数据之后会先缓存到blockcache中，再将结果返回blockcache逐渐满了之后，会采用LRU的淘汰策略。

### 1.5 MapReduce为什么一定要有Shuffle过程
因为单台机器的资源处理不了分布式大数据量全局分区/排序/分组。所以需要通过Shuffle对每一台机器的数据构建一个Task来做分区的标记（通过Hash或Ranger分区器. 这样所有的数据被标记后就可以根据标记进入指定分区，实现全局分区/分组/排序功能。

### 1.6 MapReduce中的三次排序
1. 当map函数产生输出时，会首先写入内存的环形缓冲区，当达到设定的阀值，在刷写磁盘之前，后台线程会将缓冲区的数据划分成相应的分区。在每个分区中，后台线程按键进行内排序
2. 在Map任务完成之前，磁盘上存在多个已经分好区，并排好序的，大小和缓冲区一样的溢写文件，这时溢写文件将被合并成一个已分区且已排序的输出文件。由于溢写文件已经经过第一次排序，所有合并文件只需要再做一次排序即可使输出文件整体有序。
3. 在reduce阶段，需要将多个Map任务的输出文件copy到ReduceTask中后合并，由于经过第二次排序，所以合并文件时只需再做一次排序即可使输出文件整体有序。

### 1.7 MapReduce为什么不能产生过多小文件
针对MapReduce而言，每一个小文件都是一个Block，都会产生一个InputSplit，最终每一个小文件都会 产生一个map任务，这样会导致同时启动太多的Map任务，Map任务的启动是非常消耗性能的，但是启动了以后执行了很短时间就停止了，因为小文件的数据量太小了，这样就会造成任务执行消耗的时间还没有启动任务消耗的时间多，这样也会影响MapReduce执行的效率。

## 2 代码题
暂时还没想出来，还没用过python进行mapreduce的编写，正在研究MrJob的文档